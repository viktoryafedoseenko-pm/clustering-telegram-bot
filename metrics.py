# metrics.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
"""
import numpy as np
from sklearn.metrics import (
    silhouette_score, 
    davies_bouldin_score,
    calinski_harabasz_score
)
from typing import Dict, Tuple
import logging

logger = logging.getLogger(__name__)


class ClusteringMetrics:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
    
    @staticmethod
    def calculate(embeddings, labels) -> Dict[str, float]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        
        Args:
            embeddings: –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ (N x D)
            labels: –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (N,)
        
        Returns:
            dict —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy arrays (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        embeddings = np.asarray(embeddings)
        labels = np.asarray(labels)
        
        # –£–±–∏—Ä–∞–µ–º —à—É–º (–∫–ª–∞—Å—Ç–µ—Ä -1) –¥–ª—è –º–µ—Ç—Ä–∏–∫
        mask = labels != -1
        embeddings_clean = embeddings[mask]
        labels_clean = labels[mask]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö
        unique_labels = np.unique(labels_clean)
        
        if len(unique_labels) < 2:
            logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –º–µ—Ç—Ä–∏–∫")
            noise_count = np.count_nonzero(labels == -1)
            noise_ratio = (noise_count / len(labels) * 100) if len(labels) > 0 else 0.0
            
            return {
                'silhouette_score': 0.0,
                'davies_bouldin_index': 0.0,
                'calinski_harabasz_score': 0.0,
                'noise_ratio': round(noise_ratio, 2)
            }
        
        try:
            # 1. Silhouette Score
            silhouette = silhouette_score(embeddings_clean, labels_clean)
            
            # 2. Davies-Bouldin Index
            db_index = davies_bouldin_score(embeddings_clean, labels_clean)
            
            # 3. Calinski-Harabasz Score
            ch_score = calinski_harabasz_score(embeddings_clean, labels_clean)
            
            # 4. –î–æ–ª—è —à—É–º–∞
            noise_count = np.count_nonzero(labels == -1)
            noise_ratio = (noise_count / len(labels) * 100) if len(labels) > 0 else 0.0
            
            metrics = {
                'silhouette_score': round(float(silhouette), 3),
                'davies_bouldin_index': round(float(db_index), 3),
                'calinski_harabasz_score': round(float(ch_score), 1),
                'noise_ratio': round(float(noise_ratio), 2)
            }
            
            logger.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞: {metrics}")
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ –º–µ—Ç—Ä–∏–∫: {e}", exc_info=True)
            return {
                'silhouette_score': 0.0,
                'davies_bouldin_index': 0.0,
                'calinski_harabasz_score': 0.0,
                'noise_ratio': 0.0
            }
        
    @staticmethod
    def interpret(metrics: Dict[str, float]) -> Dict[str, Tuple[str, str]]:
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            dict —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        silhouette = metrics['silhouette_score']
        db_index = metrics['davies_bouldin_index']
        ch_score = metrics['calinski_harabasz_score']
        noise = metrics['noise_ratio']
        
        # Silhouette
        if silhouette >= 0.7:
            sil_grade = ("üü¢ –û—Ç–ª–∏—á–Ω–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã —á—ë—Ç–∫–æ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã")
        elif silhouette >= 0.5:
            sil_grade = ("üü° –•–æ—Ä–æ—à–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã —Ä–∞–∑–¥–µ–ª–µ–Ω—ã, –Ω–æ –µ—Å—Ç—å –Ω–∞–ª–æ–∂–µ–Ω–∏—è")
        elif silhouette >= 0.25:
            sil_grade = ("üü† –°–ª–∞–±–æ", "–ú–Ω–æ–≥–æ –ø–æ–≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏")
        else:
            sil_grade = ("üî¥ –ü–ª–æ—Ö–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã –Ω–µ –∏–º–µ—é—Ç —á—ë—Ç–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
        
        # Davies-Bouldin
        if db_index < 0.5:
            db_grade = ("üü¢ –û—Ç–ª–∏—á–Ω–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –∏ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ")
        elif db_index < 1.0:
            db_grade = ("üü° –•–æ—Ä–æ—à–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã")
        elif db_index < 1.5:
            db_grade = ("üü† –ü—Ä–∏–µ–º–ª–µ–º–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã —á–∞—Å—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è")
        else:
            db_grade = ("üî¥ –ü–ª–æ—Ö–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã —Ä–∞–∑–º—ã—Ç—ã –∏ —Å–ª–∏–≤–∞—é—Ç—Å—è")
        
        # Calinski-Harabasz
        if ch_score > 300:
            ch_grade = ("üü¢ –û—Ç–ª–∏—á–Ω–æ", "–í—ã—Å–æ–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        elif ch_score > 100:
            ch_grade = ("üü° –•–æ—Ä–æ—à–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã —Ö–æ—Ä–æ—à–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã")
        else:
            ch_grade = ("üî¥ –°–ª–∞–±–æ", "–ö–ª–∞—Å—Ç–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–ª–æ—Ç–Ω—ã–µ")
        
        # –®—É–º
        if noise < 5:
            noise_grade = ("üü¢ –û—Ç–ª–∏—á–Ω–æ", "–ü–æ—á—Ç–∏ –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã")
        elif noise < 10:
            noise_grade = ("üü° –ù–æ—Ä–º–∞–ª—å–Ω–æ", "–ü—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞")
        elif noise < 15:
            noise_grade = ("üü† –ú–Ω–æ–≥–æ–≤–∞—Ç–æ", "–ú–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–µ –ø–æ–ø–∞–ª–æ –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã")
        else:
            noise_grade = ("üî¥ –ú–Ω–æ–≥–æ", "–°–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
        
        return {
            'silhouette': sil_grade,
            'davies_bouldin': db_grade,
            'calinski_harabasz': ch_grade,
            'noise': noise_grade
        }
    
    @staticmethod
    def format_report(metrics: Dict[str, float]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫—Ä–∞—Å–∏–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç –¥–ª—è Telegram
        
        Returns:
            HTML-formatted —Å—Ç—Ä–æ–∫–∞
        """
        interpretation = ClusteringMetrics.interpret(metrics)
        
        report = "üìä <b>–ö–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏</b>\n\n"
        
        # Silhouette
        sil_status, sil_desc = interpretation['silhouette']
        report += f"<b>–ß—ë—Ç–∫–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</b>\n"
        report += f"{sil_status} {metrics['silhouette_score']:.3f}\n"
        report += f"<i>{sil_desc}</i>\n\n"
        
        # Davies-Bouldin
        db_status, db_desc = interpretation['davies_bouldin']
        report += f"<b>–†–∞–∑–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å</b>\n"
        report += f"{db_status} {metrics['davies_bouldin_index']:.3f}\n"
        report += f"<i>{db_desc}</i>\n\n"
        
        # Calinski-Harabasz
        ch_status, ch_desc = interpretation['calinski_harabasz']
        report += f"<b>–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</b>\n"
        report += f"{ch_status} {metrics['calinski_harabasz_score']:.0f}\n"
        report += f"<i>{ch_desc}</i>\n\n"
        
        # –®—É–º
        noise_status, noise_desc = interpretation['noise']
        report += f"<b>–î–æ–ª—è —à—É–º–∞</b>\n"
        report += f"{noise_status} {metrics['noise_ratio']:.1f}%\n"
        report += f"<i>{noise_desc}</i>\n\n"
        
        # –û–±—â–∏–π –≤–µ—Ä–¥–∏–∫—Ç
        avg_quality = ClusteringMetrics._overall_quality(metrics)
        if avg_quality >= 0.7:
            verdict = "‚úÖ <b>–û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ!</b> –ö–ª–∞—Å—Ç–µ—Ä—ã —Ö–æ—Ä–æ—à–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã."
        elif avg_quality >= 0.5:
            verdict = "üëç <b>–•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ.</b> –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å."
        elif avg_quality >= 0.3:
            verdict = "‚ö†Ô∏è <b>–°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ.</b> –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."
        else:
            verdict = "‚ùå <b>–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ.</b> –ù—É–∂–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–ª–∏ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö."
        
        report += f"{verdict}"
        
        return report
    
    @staticmethod
    def _overall_quality(metrics: Dict[str, float]) -> float:
        """–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-1)"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-1
        sil_norm = max(0, metrics['silhouette_score'])  # 0-1
        db_norm = max(0, 1 - metrics['davies_bouldin_index'] / 2)  # –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        ch_norm = min(1, metrics['calinski_harabasz_score'] / 500)  # 0-1
        noise_norm = max(0, 1 - metrics['noise_ratio'] / 20)  # –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ (silhouette –≤–∞–∂–Ω–µ–µ –≤—Å–µ–≥–æ)
        return (sil_norm * 0.4 + db_norm * 0.3 + ch_norm * 0.2 + noise_norm * 0.1)
