# analytics.py
"""
–ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è Telegram –±–æ—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–æ–≤
"""
import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
import pandas as pd
from typing import Optional, Tuple
from cache_manager import cache
from pdf_generator import PDFReportGenerator
from config import TEMP_DIR

# Thread pool –¥–ª—è –±–ª–æ–∫–∏—Ä—É—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
executor = ThreadPoolExecutor(max_workers=2)

logger = logging.getLogger(__name__)

async def generate_detailed_report(
    cache_key: str,
    user_id: int
) -> Optional[Tuple[str, str]]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π PDF –æ—Ç—á—ë—Ç –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π CSV
    
    Args:
        cache_key: –ö–ª—é—á –∫—ç—à–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        user_id: Telegram user ID
    
    Returns:
        Tuple[pdf_path, csv_path] –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫—ç—à–∞
    data = cache.load(cache_key)
    if not data:
        logger.error(f"‚ùå Cache not found for key: {cache_key}")
        return None
    
    logger.info(f"‚úÖ Cache loaded: {len(data['df'])} rows, {data['stats']['n_clusters']} clusters")

    df = data['df']
    stats = data['stats']
    cluster_names = data['cluster_names']
    
    # –ü—É—Ç–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    pdf_path = TEMP_DIR / f"report_{user_id}_{cache_key[:8]}.pdf"
    csv_path = TEMP_DIR / f"extended_stats_{user_id}_{cache_key[:8]}.csv"
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ (–±–ª–æ–∫–∏—Ä—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏)
    loop = asyncio.get_event_loop()
    
    try:
        # PDF
        generator = PDFReportGenerator(df, stats, cluster_names)
        success = await loop.run_in_executor(
            executor,
            generator.generate,
            str(pdf_path)
        )
        
        if not success:
            return None
        
        # Extended CSV
        await loop.run_in_executor(
            executor,
            _generate_extended_csv,
            df, cluster_names, str(csv_path)
        )
        
        return str(pdf_path), str(csv_path)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error generating report: {e}")
        return None

def _generate_extended_csv(df: pd.DataFrame, cluster_names: dict, output_path: str):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ CSV"""
    import logging
    logger = logging.getLogger(__name__)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if df.empty:
            logger.error("‚ùå DataFrame is empty")
            raise ValueError("Empty DataFrame")
        
        if 'cluster_id' not in df.columns:
            logger.error(f"‚ùå 'cluster_id' column not found. Available: {df.columns.tolist()}")
            raise ValueError("cluster_id column missing")
        
        # –ü–æ–¥—Å—á—ë—Ç
        logger.info(f"üìä Calculating stats for {len(df)} rows")
        cluster_counts = df['cluster_id'].value_counts().sort_values(ascending=False)
        
        logger.info(f"üìä Found {len(cluster_counts)} clusters")
        
        # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É
        stats_data = []
        
        for cluster_id, size in cluster_counts.items():
            # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
            name = cluster_names.get(cluster_id, f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}")
            
            # –ü—Ä–æ—Ü–µ–Ω—Ç
            percent = round((size / len(df)) * 100, 2)
            
            stats_data.append({
                'cluster_id': cluster_id,
                'cluster_name': name,
                'size': int(size),
                'percent': percent
            })
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        cluster_stats = pd.DataFrame(stats_data)
        cluster_stats.to_csv(output_path, index=False, encoding='utf-8')
        
        logger.info(f"‚úÖ Extended CSV saved: {output_path}")
        
    except Exception as e:
        logger.error(f"‚ùå Error in _generate_extended_csv: {e}", exc_info=True)
        raise
